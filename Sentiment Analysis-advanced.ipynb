{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a6a0d0-fdb7-4291-a185-7da1c812d08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e344ee6e-526f-4168-b014-ee566a678c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf8325b-b6d2-4a35-935b-503b84e4d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (1% of the training set)\n",
    "dataset = load_dataset('amazon_polarity', split='train[:1%]')\n",
    "\n",
    "# Split dataset into train and test\n",
    "split = dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = split['train']\n",
    "test_dataset = split['test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00dcbf5-f5fe-4259-8d8d-de10a2cdf02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['content'], padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=32)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True, batch_size=32)\n",
    "\n",
    "# Set formats for PyTorch\n",
    "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee5393f-d8c9-4151-94f0-c7f2ff27c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fa270d-0379-48a3-b53d-4e4c3fc32b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {'accuracy': acc, 'f1': f1, 'precision': precision, 'recall': recall}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1779eb5e-a879-487a-ad77-98a86a3194ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    "    report_to=[]  # Disable all integrations including wandb\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ca26fc-a5d3-483a-9a86-7d18576934a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a650df39-d120-4589-8759-23f8506f6ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metrics = trainer.state.log_history\n",
    "\n",
    "# Extract train and eval loss with indices\n",
    "train_loss = [x['loss'] for x in metrics if 'loss' in x]\n",
    "eval_metrics = [(i, x['eval_loss']) for i, x in enumerate(metrics) if 'eval_loss' in x]\n",
    "\n",
    "# Separate indices and values for eval loss\n",
    "eval_steps, eval_loss = zip(*eval_metrics) if eval_metrics else ([], [])\n",
    "\n",
    "steps = range(len(train_loss))\n",
    "\n",
    "plt.plot(steps, train_loss, label=\"Train Loss\")\n",
    "if eval_metrics:\n",
    "    plt.plot(eval_steps, eval_loss, label=\"Eval Loss\")\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Evaluation Loss Over Steps')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871168e3-08ee-4ea8-88b0-0b733863e622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select test samples - first 5 rows for instance\n",
    "test_samples = test_dataset.select(range(5))  # Assuming test_dataset is available\n",
    "\n",
    "# Run prediction on those samples using your trainer\n",
    "preds = trainer.predict(test_samples)\n",
    "\n",
    "# Extract predicted class labels from model output logits\n",
    "predicted_labels = preds.predictions.argmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce5da3a-e002-4c26-b402-18c48070a55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(test_samples):\n",
    "    for key in ['title', 'content']:\n",
    "        if key in sample:\n",
    "            print(f\"{key.capitalize()}: {sample[key]}\")\n",
    "    print(f\"True Label: {sample['label']}, Predicted: {predicted_labels[i]}\")\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62788490-c527-40f6-aa8e-de13e5a1fcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = trainer.evaluate(eval_dataset=test_dataset)\n",
    "print(\"Evaluation results:\", eval_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b735a0-22fe-49e1-ab6f-e51f892d658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('./fine_tuned_bert_amazon')\n",
    "tokenizer.save_pretrained('./fine_tuned_bert_amazon')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
